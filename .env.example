# Model Configuration
# Set USE_OLLAMA=true to use Ollama instead of OpenAI
USE_OLLAMA=false

# OpenAI API Configuration (required when USE_OLLAMA=false)
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (used when USE_OLLAMA=true)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Optional: LangSmith Configuration for observability
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key_here